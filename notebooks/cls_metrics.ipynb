{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\pytorch_venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "book_names = ['ferdydurke','gombrowicz diary', 'gombrowicz diary_2','gombrowicz diary_3', 'gombrowicz-cosmospdf']\n",
    "\n",
    "df_g = pd.concat([pd.read_csv(f\"./input/processed_books/{book_name}.csv\", sep = \";\") for book_name in book_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context1</th>\n",
       "      <th>context2</th>\n",
       "      <th>context3</th>\n",
       "      <th>context4</th>\n",
       "      <th>context5</th>\n",
       "      <th>context6</th>\n",
       "      <th>context7</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>And this is only a foretaste of insolence to c...</td>\n",
       "      <td>Published in late 1937, when its author was th...</td>\n",
       "      <td>The title of his first,  Memoirs of a Time of ...</td>\n",
       "      <td>Perhaps this is why Gombrowicz opted for jabbe...</td>\n",
       "      <td>That first book, whose title was pounced on by...</td>\n",
       "      <td>Had the title of his volume of fanciful storie...</td>\n",
       "      <td>Now he would  really provoke.</td>\n",
       "      <td>Published in late 1937, when its author was th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Published in late 1937, when its author was th...</td>\n",
       "      <td>The title of his first,  Memoirs of a Time of ...</td>\n",
       "      <td>Perhaps this is why Gombrowicz opted for jabbe...</td>\n",
       "      <td>That first book, whose title was pounced on by...</td>\n",
       "      <td>Had the title of his volume of fanciful storie...</td>\n",
       "      <td>Now he would  really provoke.</td>\n",
       "      <td>He would write an epic in defense of immaturity.</td>\n",
       "      <td>The title of his first,  Memoirs of a Time of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The title of his first,  Memoirs of a Time of ...</td>\n",
       "      <td>Perhaps this is why Gombrowicz opted for jabbe...</td>\n",
       "      <td>That first book, whose title was pounced on by...</td>\n",
       "      <td>Had the title of his volume of fanciful storie...</td>\n",
       "      <td>Now he would  really provoke.</td>\n",
       "      <td>He would write an epic in defense of immaturity.</td>\n",
       "      <td>As he declared toward the end of his life: \"Im...</td>\n",
       "      <td>Perhaps this is why Gombrowicz opted for jabbe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            context1  \\\n",
       "0  And this is only a foretaste of insolence to c...   \n",
       "1  Published in late 1937, when its author was th...   \n",
       "2  The title of his first,  Memoirs of a Time of ...   \n",
       "\n",
       "                                            context2  \\\n",
       "0  Published in late 1937, when its author was th...   \n",
       "1  The title of his first,  Memoirs of a Time of ...   \n",
       "2  Perhaps this is why Gombrowicz opted for jabbe...   \n",
       "\n",
       "                                            context3  \\\n",
       "0  The title of his first,  Memoirs of a Time of ...   \n",
       "1  Perhaps this is why Gombrowicz opted for jabbe...   \n",
       "2  That first book, whose title was pounced on by...   \n",
       "\n",
       "                                            context4  \\\n",
       "0  Perhaps this is why Gombrowicz opted for jabbe...   \n",
       "1  That first book, whose title was pounced on by...   \n",
       "2  Had the title of his volume of fanciful storie...   \n",
       "\n",
       "                                            context5  \\\n",
       "0  That first book, whose title was pounced on by...   \n",
       "1  Had the title of his volume of fanciful storie...   \n",
       "2                      Now he would  really provoke.   \n",
       "\n",
       "                                            context6  \\\n",
       "0  Had the title of his volume of fanciful storie...   \n",
       "1                      Now he would  really provoke.   \n",
       "2   He would write an epic in defense of immaturity.   \n",
       "\n",
       "                                            context7  \\\n",
       "0                      Now he would  really provoke.   \n",
       "1   He would write an epic in defense of immaturity.   \n",
       "2  As he declared toward the end of his life: \"Im...   \n",
       "\n",
       "                                            response  \n",
       "0  Published in late 1937, when its author was th...  \n",
       "1  The title of his first,  Memoirs of a Time of ...  \n",
       "2  Perhaps this is why Gombrowicz opted for jabbe...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_g.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "data_g = df_g['response'].tolist()\n",
    "data = random.sample(data_g, 11000)\n",
    "labels_g = [1] * len(data)\n",
    "\n",
    "style_names=['aae', 'bible', 'coha_1810-1830', 'coha_1890-1910', 'coha_1990-2000', 'english_tweets', 'joyce', 'lyrics', 'romantic_poetry', 'shakespeare', 'switchboard']\n",
    "\n",
    "data_o = np.array([open(os.path.join(\"./style_samples\", style + \".txt\"), \"r\").read().splitlines() for style in style_names]).flatten()\n",
    "labels_o = [0] * len(data_o)\n",
    "\n",
    "data.extend(data_o)\n",
    "labels = labels_g + labels_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(data, labels, test_size=0.3)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatbot.classifier import Classifier\n",
    "\n",
    "classifier = Classifier(model_path='./roberta-checkpoint/', device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "predictions = []\n",
    "for text in test_texts:\n",
    "    prediction = classifier.get_prediction(text)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "F1 score: 0.94999499949995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "print(f'F1 score: {f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
